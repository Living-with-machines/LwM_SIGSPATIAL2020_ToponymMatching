{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Ranking experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from haversine import haversine\n",
    "import time\n",
    "import ast\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from find_deezymatch_candidates import find_deezymatch_candidates\n",
    "from find_levdam_candidates import find_levdam_candidates\n",
    "from evaluation_functions import evaluate_ranking\n",
    "from evaluation_functions import map_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Candidate Selection methods on different datasets (table 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ArgManuscrita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 1 candidate\n",
      "EXACT P@1 0.69\n",
      "DM P@1 0.78\n",
      "LD P@1 0.78\n",
      "\n",
      "* 5 candidates\n",
      "DM MAP 0.78\n",
      "LD MAP 0.77\n",
      "\n",
      "* 10 candidates\n",
      "DM MAP 0.76\n",
      "LD MAP 0.72\n",
      "\n",
      "* 20 candidates\n",
      "DM MAP 0.74\n",
      "LD MAP 0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gazetteer_name = \"wikigaz_hgisindias_es\"\n",
    "candrank_dataset = \"argentina_manuscrita\"\n",
    "deezymatch_model = \"wikigaz_es_001\"\n",
    "\n",
    "# Find DeezyMatch candidates:\n",
    "find_deezymatch_candidates(gazetteer_name, candrank_dataset, deezymatch_model)\n",
    "\n",
    "# Find Levenshtein-Damerau candidates:\n",
    "find_levdam_candidates(gazetteer_name, candrank_dataset)\n",
    "\n",
    "# Rank candidates:\n",
    "evaluate_ranking(gazetteer_name, candrank_dataset, deezymatch_model)\n",
    "print(\"* 1 candidate\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 1)\n",
    "print(\"* 5 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 5)\n",
    "print(\"* 10 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 10)\n",
    "print(\"* 20 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. WOTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 1 candidate\n",
      "EXACT P@1 0.86\n",
      "DM P@1 0.93\n",
      "LD P@1 0.92\n",
      "\n",
      "* 5 candidates\n",
      "DM MAP 0.92\n",
      "LD MAP 0.89\n",
      "\n",
      "* 10 candidates\n",
      "DM MAP 0.9\n",
      "LD MAP 0.84\n",
      "\n",
      "* 20 candidates\n",
      "DM MAP 0.87\n",
      "LD MAP 0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gazetteer_name = \"wikigaz_en\"\n",
    "candrank_dataset = \"wotr_test\"\n",
    "deezymatch_model = \"wikigaz_en_001\"\n",
    "\n",
    "# Find DeezyMatch candidates:\n",
    "find_deezymatch_candidates(gazetteer_name, candrank_dataset, deezymatch_model)\n",
    "\n",
    "# Find Levenshtein-Damerau candidates:\n",
    "find_levdam_candidates(gazetteer_name, candrank_dataset)\n",
    "\n",
    "# Rank candidates:\n",
    "evaluate_ranking(gazetteer_name, candrank_dataset, deezymatch_model)\n",
    "print(\"* 1 candidate\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 1)\n",
    "print(\"* 5 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 5)\n",
    "print(\"* 10 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 10)\n",
    "print(\"* 20 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. FMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 1 candidate\n",
      "EXACT P@1 0.77\n",
      "DM P@1 0.85\n",
      "LD P@1 0.92\n",
      "\n",
      "* 5 candidates\n",
      "DM MAP 0.85\n",
      "LD MAP 0.88\n",
      "\n",
      "* 10 candidates\n",
      "DM MAP 0.82\n",
      "LD MAP 0.82\n",
      "\n",
      "* 20 candidates\n",
      "DM MAP 0.78\n",
      "LD MAP 0.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gazetteer_name = \"wikigaz_en\"\n",
    "candrank_dataset = \"fmp\"\n",
    "deezymatch_model = \"wikigaz_en_001\"\n",
    "\n",
    "# Find DeezyMatch candidates:\n",
    "find_deezymatch_candidates(gazetteer_name, candrank_dataset, deezymatch_model)\n",
    "\n",
    "# Find Levenshtein-Damerau candidates:\n",
    "find_levdam_candidates(gazetteer_name, candrank_dataset)\n",
    "\n",
    "# Rank candidates:\n",
    "evaluate_ranking(gazetteer_name, candrank_dataset, deezymatch_model)\n",
    "print(\"* 1 candidate\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 1)\n",
    "print(\"* 5 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 5)\n",
    "print(\"* 10 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 10)\n",
    "print(\"* 20 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 1 candidate\n",
      "EXACT P@1 0.77\n",
      "DM P@1 0.83\n",
      "LD P@1 0.92\n",
      "\n",
      "* 5 candidates\n",
      "DM MAP 0.83\n",
      "LD MAP 0.88\n",
      "\n",
      "* 10 candidates\n",
      "DM MAP 0.82\n",
      "LD MAP 0.82\n",
      "\n",
      "* 20 candidates\n",
      "DM MAP 0.8\n",
      "LD MAP 0.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gazetteer_name = \"wikigaz_en\"\n",
    "candrank_dataset = \"fmp\"\n",
    "deezymatch_model = \"ocr_001\"\n",
    "\n",
    "# Find DeezyMatch candidates:\n",
    "find_deezymatch_candidates(gazetteer_name, candrank_dataset, deezymatch_model)\n",
    "\n",
    "# Find Levenshtein-Damerau candidates:\n",
    "find_levdam_candidates(gazetteer_name, candrank_dataset)\n",
    "\n",
    "# Rank candidates:\n",
    "evaluate_ranking(gazetteer_name, candrank_dataset, deezymatch_model)\n",
    "print(\"* 1 candidate\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 1)\n",
    "print(\"* 5 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 5)\n",
    "print(\"* 10 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 10)\n",
    "print(\"* 20 candidates\")\n",
    "map_score(gazetteer_name, candrank_dataset, deezymatch_model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37deezy)",
   "language": "python",
   "name": "py37deezy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
