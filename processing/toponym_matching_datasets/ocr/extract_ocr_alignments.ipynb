{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [!] Preliminary note\n",
    "\n",
    "You can skip this notebook and instead download the `.tsv` required for the experiments directly from [here](https://zenodo.org/record/4034819). Store the file `ocrTokens.tsv` in the `processing/resources/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataset for OCR'd text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import ast\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load alignments\n",
    "\n",
    "Load dataframe with the alignments generated by [this notebook](https://github.com/Living-with-machines/lwm_ARTIDIGH_2020_OCR_impact_downstream_NLP_tasks/blob/master/aligning_trove.ipynb) and containing spaCy's processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../resources/aligned_df_with_spacy.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>articleId</th>\n",
       "      <th>articleType</th>\n",
       "      <th>year</th>\n",
       "      <th>ocrText</th>\n",
       "      <th>humanText</th>\n",
       "      <th>corrected</th>\n",
       "      <th>str_similarity</th>\n",
       "      <th>str_length</th>\n",
       "      <th>alignment</th>\n",
       "      <th>processed</th>\n",
       "      <th>spacyOcr</th>\n",
       "      <th>spacyHum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18378453</td>\n",
       "      <td>Article ILLUSTRATED</td>\n",
       "      <td>1953</td>\n",
       "      <td>FROM RIVER CROSSING TO END OF TRIÄÜ I ^PI A^H\"...</td>\n",
       "      <td>FROM RIVER CROSSING TO END OF TRIAL SPLASH: Pe...</td>\n",
       "      <td></td>\n",
       "      <td>0.847747</td>\n",
       "      <td>747</td>\n",
       "      <td>[(0, 4, 0, 4), (5, 10, 5, 10), (11, 19, 11, 19...</td>\n",
       "      <td>yes</td>\n",
       "      <td>(FROM, RIVER, CROSSING, TO, END, OF, TRIÄÜ, I,...</td>\n",
       "      <td>(FROM, RIVER, CROSSING, TO, END, OF, TRIAL, SP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18363627</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>Natural Childbirth Sir,-We nurses have seen fa...</td>\n",
       "      <td>Natural Childbirth Sir,-We nurses have seen fa...</td>\n",
       "      <td></td>\n",
       "      <td>0.964174</td>\n",
       "      <td>642</td>\n",
       "      <td>[(0, 7, 0, 7), (8, 18, 8, 18), (19, 26, 19, 26...</td>\n",
       "      <td>yes</td>\n",
       "      <td>(Natural, Childbirth, Sir,-We, nurses, have, s...</td>\n",
       "      <td>(Natural, Childbirth, Sir,-We, nurses, have, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18368961</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>DIVORCE Before The Judge In Divorce, Mr Justic...</td>\n",
       "      <td>DIVORCE Before The Judge In Divorce, Mr. Justi...</td>\n",
       "      <td></td>\n",
       "      <td>0.894262</td>\n",
       "      <td>1220</td>\n",
       "      <td>[(0, 7, 0, 7), (8, 14, 8, 14), (19, 24, 19, 24...</td>\n",
       "      <td>yes</td>\n",
       "      <td>(DIVORCE, Before, The, Judge, In, Divorce, ,, ...</td>\n",
       "      <td>(DIVORCE, Before, The, Judge, In, Divorce, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18381450</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>I SCHOOL CHESS * Homebush Increased Ils lead o...</td>\n",
       "      <td>SCHOOL CHESS  Homebush increased its lead over...</td>\n",
       "      <td></td>\n",
       "      <td>0.918347</td>\n",
       "      <td>992</td>\n",
       "      <td>[(2, 8, 0, 6), (9, 14, 7, 12), (17, 25, 14, 22...</td>\n",
       "      <td>yes</td>\n",
       "      <td>(I, SCHOOL, CHESS, *, Homebush, Increased, Ils...</td>\n",
       "      <td>(SCHOOL, CHESS,  , Homebush, increased, its, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>./trove_overproof/datasets/dataset1/rawTextAnd...</td>\n",
       "      <td>18383206</td>\n",
       "      <td>Article</td>\n",
       "      <td>1953</td>\n",
       "      <td>Architects' Contracts Architects have signed t...</td>\n",
       "      <td>Architects' Contracts Architects have signed t...</td>\n",
       "      <td></td>\n",
       "      <td>0.897167</td>\n",
       "      <td>953</td>\n",
       "      <td>[(0, 11, 0, 11), (12, 21, 12, 21), (22, 32, 22...</td>\n",
       "      <td>yes</td>\n",
       "      <td>(Architects, ', Contracts, Architects, have, s...</td>\n",
       "      <td>(Architects, ', Contracts, Architects, have, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filePath articleId  \\\n",
       "1  ./trove_overproof/datasets/dataset1/rawTextAnd...  18378453   \n",
       "2  ./trove_overproof/datasets/dataset1/rawTextAnd...  18363627   \n",
       "5  ./trove_overproof/datasets/dataset1/rawTextAnd...  18368961   \n",
       "7  ./trove_overproof/datasets/dataset1/rawTextAnd...  18381450   \n",
       "8  ./trove_overproof/datasets/dataset1/rawTextAnd...  18383206   \n",
       "\n",
       "            articleType  year  \\\n",
       "1  Article ILLUSTRATED   1953   \n",
       "2               Article  1953   \n",
       "5               Article  1953   \n",
       "7               Article  1953   \n",
       "8               Article  1953   \n",
       "\n",
       "                                             ocrText  \\\n",
       "1  FROM RIVER CROSSING TO END OF TRIÄÜ I ^PI A^H\"...   \n",
       "2  Natural Childbirth Sir,-We nurses have seen fa...   \n",
       "5  DIVORCE Before The Judge In Divorce, Mr Justic...   \n",
       "7  I SCHOOL CHESS * Homebush Increased Ils lead o...   \n",
       "8  Architects' Contracts Architects have signed t...   \n",
       "\n",
       "                                           humanText corrected  \\\n",
       "1  FROM RIVER CROSSING TO END OF TRIAL SPLASH: Pe...             \n",
       "2  Natural Childbirth Sir,-We nurses have seen fa...             \n",
       "5  DIVORCE Before The Judge In Divorce, Mr. Justi...             \n",
       "7  SCHOOL CHESS  Homebush increased its lead over...             \n",
       "8  Architects' Contracts Architects have signed t...             \n",
       "\n",
       "   str_similarity  str_length  \\\n",
       "1        0.847747         747   \n",
       "2        0.964174         642   \n",
       "5        0.894262        1220   \n",
       "7        0.918347         992   \n",
       "8        0.897167         953   \n",
       "\n",
       "                                           alignment processed  \\\n",
       "1  [(0, 4, 0, 4), (5, 10, 5, 10), (11, 19, 11, 19...       yes   \n",
       "2  [(0, 7, 0, 7), (8, 18, 8, 18), (19, 26, 19, 26...       yes   \n",
       "5  [(0, 7, 0, 7), (8, 14, 8, 14), (19, 24, 19, 24...       yes   \n",
       "7  [(2, 8, 0, 6), (9, 14, 7, 12), (17, 25, 14, 22...       yes   \n",
       "8  [(0, 11, 0, 11), (12, 21, 12, 21), (22, 32, 22...       yes   \n",
       "\n",
       "                                            spacyOcr  \\\n",
       "1  (FROM, RIVER, CROSSING, TO, END, OF, TRIÄÜ, I,...   \n",
       "2  (Natural, Childbirth, Sir,-We, nurses, have, s...   \n",
       "5  (DIVORCE, Before, The, Judge, In, Divorce, ,, ...   \n",
       "7  (I, SCHOOL, CHESS, *, Homebush, Increased, Ils...   \n",
       "8  (Architects, ', Contracts, Architects, have, s...   \n",
       "\n",
       "                                            spacyHum  \n",
       "1  (FROM, RIVER, CROSSING, TO, END, OF, TRIAL, SP...  \n",
       "2  (Natural, Childbirth, Sir,-We, nurses, have, s...  \n",
       "5  (DIVORCE, Before, The, Judge, In, Divorce, ,, ...  \n",
       "7  (SCHOOL, CHESS,  , Homebush, increased, its, l...  \n",
       "8  (Architects, ', Contracts, Architects, have, s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28287, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find tokens belonging to certain entities that contain OCR errors\n",
    "\n",
    "**Notes:**\n",
    "* The `target` argument expects one of these strings:\n",
    "    * `correct`: if OCR'd token and human-corrected token are identical.\n",
    "    * `incorrect`: if OCR'd token is different from human-corrected (i.e. there is an OCR error in the token).\n",
    "    * `all`: all token alignments, regardless of whether the OCR contains errors.\n",
    "* The `targetLabels` argument expects the list of entity types supported by spaCy NER module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateNer(dirtyText, cleanText, spacyDirtyText, spacyCleanText, absoluteIndexLinking, target, targetLabels):\n",
    "    \n",
    "    allAlignedPairs = []\n",
    "    \n",
    "    dDirtyTokenNer = dict()\n",
    "    for token in spacyDirtyText:\n",
    "        tokenIndicesNer = token.idx\n",
    "        dDirtyTokenNer[tokenIndicesNer] = (token.ent_iob_, token.ent_type_, token.text)\n",
    "        \n",
    "    dCleanTokenNer = dict()\n",
    "    for token in spacyCleanText:\n",
    "        tokenIndicesNer = token.idx\n",
    "        dCleanTokenNer[tokenIndicesNer] = (token.ent_iob_, token.ent_type_, token.text)\n",
    "    \n",
    "    for matched_word in absoluteIndexLinking:\n",
    "        if matched_word[0] in dDirtyTokenNer and matched_word[2] in dCleanTokenNer:\n",
    "            labelOcr = dDirtyTokenNer[matched_word[0]][1].strip()\n",
    "            labelHum = dCleanTokenNer[matched_word[2]][1].strip()\n",
    "            ocrWord = dDirtyTokenNer[matched_word[0]][2]\n",
    "            humWord = dCleanTokenNer[matched_word[2]][2]\n",
    "            \n",
    "            target_condition = False\n",
    "            if target == \"correct\":\n",
    "                if ocrWord.lower() == humWord.lower():\n",
    "                    target_condition = True\n",
    "            if target == \"incorrect\":\n",
    "                if ocrWord.lower() != humWord.lower():\n",
    "                    target_condition = True\n",
    "            if target == \"all\":\n",
    "                target_condition = True\n",
    "            \n",
    "            if target_condition == True:\n",
    "                if labelHum in targetLabels:\n",
    "                    # We are not interested in errors due to bad tokenisation,\n",
    "                    # filter out tokens with only one character,\n",
    "                    # filter out word with - (hyphenated),\n",
    "                    # human-corrected token's first character is capitalised,\n",
    "                    # and human-corrected token contains no number in it:\n",
    "                    if not ocrWord in humWord and not humWord in ocrWord and len(ocrWord) > 1 and not '-' in humWord and humWord[0].isupper() and not any(map(str.isdigit, humWord)):\n",
    "                        allAlignedPairs.append((ocrWord, humWord))\n",
    "\n",
    "    return allAlignedPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target token:\n",
    "# * \"correct\" if identical between OCR'd and human-corrected counterpart,\n",
    "# * \"incorrect\" if OCR'd token is different from human-corrected,\n",
    "# * \"all\" if we don't care.\n",
    "\n",
    "alignedEntities = []\n",
    "target = \"incorrect\"\n",
    "\n",
    "labels = ['GPE', 'LOC', 'NORP', 'FAC', 'ORG', 'PERSON', 'PRODUCT', 'EVENT', 'WORK_OF_ART', 'LANGUAGE']\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    if row['alignment'] != \"\":\n",
    "        ocrText = row['ocrText'].strip(\" \")\n",
    "        humanText = row['corrected'].strip(\" \")\n",
    "        spacyOcr = row['spacyOcr']\n",
    "        spacyHum = row['spacyHum']\n",
    "        alignment = ast.literal_eval(row['alignment'])\n",
    "        alignedEntities += evaluateNer(ocrText, humanText, spacyOcr, spacyHum, alignment, target, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140313\n"
     ]
    }
   ],
   "source": [
    "print(len(alignedEntities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../resources/ocrTokens.tsv', mode='w') as ocrToponyms:\n",
    "    ocrToponyms_writer = csv.writer(ocrToponyms, delimiter='\\t')\n",
    "    for ent in alignedEntities:\n",
    "        ocrToponyms_writer.writerow([ent[0], ent[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_allennlp",
   "language": "python",
   "name": "python_allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
